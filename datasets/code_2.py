# -*- coding: utf-8 -*-
"""code_2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zvJhw5gbM7DwkXCIGQaF4H4p0Gb_YQqt
"""

import os
import chardet
import codecs
import re

def convert_txt_to_utf8(root_dir):
    """
    Recursively converts all TXT files in the given directory and its subdirectories
    to UTF-8 encoding, removing any non-UTF-8 characters.

    Args:
        root_dir (str): The root directory to start the conversion from.
    """

    for root, _, files in os.walk(root_dir):
        for filename in files:
            if filename.endswith(".txt"):
                filepath = os.path.join(root, filename)

                try:
                    # 1. Detect the current encoding
                    with open(filepath, 'rb') as f:
                        raw_data = f.read()
                        result = chardet.detect(raw_data)
                        source_encoding = result['encoding']

                    if source_encoding is None:
                        print(f"Skipping {filepath}: Unable to detect encoding.")
                        continue # Skip to the next file

                    # Handle cases where chardet returns "None" or other non-standard names
                    if source_encoding.lower() == "ascii":
                        print(f"Skipping {filepath}: Already in ASCII (compatible with UTF-8).")
                        continue


                    # 2. Read the file with the detected encoding
                    try:
                        with codecs.open(filepath, 'r', encoding=source_encoding, errors='replace') as f:
                            content = f.read()  # Read the content
                    except LookupError:
                        print(f"Skipping {filepath}: Unknown encoding '{source_encoding}'.")
                        continue
                    except Exception as e:
                        print(f"Error reading {filepath} with encoding {source_encoding}: {e}")
                        continue


                    # 3. Remove non-UTF-8 characters
                    content = re.sub(r'[^\x00-\x7F]+', '', content) # Remove anything outside the basic ASCII range.  This is a SIMPLE approach.
                    # content = re.sub(r'[^\u0000-\uFFFF]+', '', content)  # Remove characters outside the basic multilingual plane (BMP) - MORE COMPLEX.


                    # 4. Write the content back to the file with UTF-8 encoding
                    try:
                        with codecs.open(filepath, 'w', encoding='utf-8', errors='replace') as f:
                            f.write(content)
                    except Exception as e:
                         print(f"Error writing {filepath} in UTF-8: {e}")
                         continue


                    print(f"Converted {filepath} from {source_encoding} to UTF-8 (and cleaned).")

                except Exception as e:
                    print(f"Error processing {filepath}: {e}")




# Example usage:
if __name__ == "__main__":
    # Replace 'path/to/your/directory' with the actual directory path
    directory_to_convert = 'path/to/your/directory'
    convert_txt_to_utf8(directory_to_convert)
    print("Conversion process completed.")